{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cee564f-437e-4462-b316-e5032167e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load completed\n",
      "Processing input_images\\input_images.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 759s/step\n",
      "Enhanced images saved to output_images\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m enhance_images_in_directory(input_folder, output_folder)\n\u001b[0;32m     58\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 59\u001b[0m y_enhanced \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(y)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "def load_srcnn_model():\n",
    "    input_shape = (None, None, 1)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv1 = tf.keras.layers.Conv2D(128, (9, 9), activation='relu', padding='same')(inputs)\n",
    "    conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    outputs = tf.keras.layers.Conv2D(1, (5, 5), padding='same')(conv2)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.load_weights(r'srcnn_weights.h5')  # 사전 학습된 가중치 파일의 경로\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def enhance_image(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    y, cr, cb = cv2.split(image)\n",
    "    y = y.astype(np.float32) / 255.0\n",
    "    y = np.expand_dims(np.expand_dims(y, axis=0), axis=-1)\n",
    "    y_enhanced = model.predict(y)\n",
    "    y_enhanced = y_enhanced[0, :, :, 0]\n",
    "    y_enhanced = (y_enhanced * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    enhanced_image = cv2.merge([y_enhanced, cr, cb])\n",
    "    enhanced_image = cv2.cvtColor(enhanced_image, cv2.COLOR_YCrCb2BGR)\n",
    "    return enhanced_image\n",
    "\n",
    "def enhance_images_in_directory(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    srcnn_model = load_srcnn_model()\n",
    "    print('model load completed')\n",
    "    \n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for idx, image_file in enumerate(image_files):\n",
    "        image_path = os.path.join(input_folder, image_file)\n",
    "        print(f\"Processing {image_path}\")\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is not None:\n",
    "            enhanced_image = enhance_image(image, srcnn_model)\n",
    "            output_path = os.path.join(output_folder, f\"enhanced_{idx:04d}.jpg\")\n",
    "            cv2.imwrite(output_path, enhanced_image)\n",
    "    \n",
    "    print(f\"Enhanced images saved to {output_folder}\")\n",
    "\n",
    "# 실행 예제 (현재 폴더 기준으로 input_images / output_images 폴더 사용)\n",
    "input_folder = r'input_images'\n",
    "output_folder = r'output_images'\n",
    "enhance_images_in_directory(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08ef7c2-91a7-4603-a36f-b927d38d0927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ymshin input_folder input_images\n",
      "ymshin for 0 input_images.png\n",
      "ymshin image_path = input_images\\input_images.png\n",
      "Image path exists. 이미지 있음\n",
      "img is not none 있어서 go\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "import gc\n",
    "\n",
    "def load_srcnn_model():\n",
    "    input_shape = (None, None, 1)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv1 = tf.keras.layers.Conv2D(128, (9, 9), activation='relu', padding='same')(inputs)\n",
    "    conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    outputs = tf.keras.layers.Conv2D(1, (5, 5), padding='same')(conv2)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.load_weights(r'srcnn_weights.h5')  # 사전 학습된 가중치 파일의 경로\n",
    "    return model\n",
    "\n",
    "def enhance_image(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    y, cr, cb = cv2.split(image)\n",
    "    y = y.astype(np.float32) / 255.0\n",
    "    y = np.expand_dims(np.expand_dims(y, axis=0), axis=-1)\n",
    "    y_enhanced = model.predict(y)\n",
    "    y_enhanced = y_enhanced[0, :, :, 0]\n",
    "    y_enhanced = (y_enhanced * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    enhanced_image = cv2.merge([y_enhanced, cr, cb])\n",
    "    enhanced_image = cv2.cvtColor(enhanced_image, cv2.COLOR_YCrCb2BGR)\n",
    "    return enhanced_image\n",
    "\n",
    "def enhance_images_in_directory(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    srcnn_model = load_srcnn_model()\n",
    "\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.JPG'))]\n",
    "\n",
    "    for idx, image_file in enumerate(image_files):\n",
    "        print(f\"ymshin input_folder {input_folder}\")\n",
    "        print(f\"ymshin for {idx} {image_file}\")\n",
    "        image_path = os.path.join(input_folder, image_file)\n",
    "        print(f\"ymshin image_path = {image_path}\")\n",
    "        if os.path.exists(image_path):\n",
    "            print(\"Image path exists. 이미지 있음\")\n",
    "        else:\n",
    "            print(\"Image path does not exist. Check the path.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is not None:\n",
    "            print(\"img is not none 있어서 go\")\n",
    "            enhanced_image = enhance_image(image, srcnn_model)\n",
    "            output_path = os.path.join(output_folder, f\"enhanced_{idx:04d}.jpg\")\n",
    "            cv2.imwrite(output_path, enhanced_image)\n",
    "\n",
    "            # 메모리 해제\n",
    "            del image\n",
    "            del enhanced_image\n",
    "            gc.collect()\n",
    "\n",
    "        # TensorFlow 세션을 주기적으로 클리어\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    print(f\"Enhanced images saved to {output_folder}\")\n",
    "\n",
    "# 사용 예제\n",
    "input_folder = r'input_images'\n",
    "output_folder = r'output_images'\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "                gpu,\n",
    "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]  # 원하는 메모리 크기로 설정\n",
    "            )\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "enhance_images_in_directory(input_folder, output_folder)\n",
    "\n",
    "# GPU 메모리 클리어 (전체 작업이 끝난 후)\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "\n",
    "# TensorFlow 세션 종료 (전체 작업이 끝난 후)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa58769b-6ce5-4a2e-a267-76be7b0f5d39",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Using cached numba-0.61.2-cp310-cp310-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba)\n",
      "  Using cached llvmlite-0.44.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<2.3,>=1.24 in c:\\users\\yjyoo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba) (2.1.3)\n",
      "Downloading numba-0.61.2-cp310-cp310-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.6/2.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 6.6 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.44.0-cp310-cp310-win_amd64.whl (30.3 MB)\n",
      "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/30.3 MB 7.2 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.9/30.3 MB 7.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 5.0/30.3 MB 8.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 7.3/30.3 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 9.4/30.3 MB 9.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 11.5/30.3 MB 9.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 12.1/30.3 MB 8.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 13.9/30.3 MB 8.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 16.0/30.3 MB 8.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 17.8/30.3 MB 8.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 20.2/30.3 MB 8.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 22.3/30.3 MB 8.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 24.6/30.3 MB 9.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 26.7/30.3 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 28.6/30.3 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.3/30.3 MB 9.0 MB/s eta 0:00:00\n",
      "Installing collected packages: llvmlite, numba\n",
      "\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   ---------------------------------------- 2/2 [numba]\n",
      "\n",
      "Successfully installed llvmlite-0.44.0 numba-0.61.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0f1aa-623f-4f0e-bc20-886593e9256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "def load_srcnn_model():\n",
    "    inputs = Input(shape=(None, None, 1))\n",
    "    x = tf.keras.layers.Conv2D(128, (9, 9), activation='relu', padding='same')(inputs)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    outputs = tf.keras.layers.Conv2D(1, (5, 5), padding='same')(x)\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    model.load_weights('srcnn_weights.h5')  # 같은 폴더에 있어야 함\n",
    "    return model\n",
    "\n",
    "def enhance_image(image, model):\n",
    "    image_ycc = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    y, cr, cb = cv2.split(image_ycc)\n",
    "    y = y.astype(np.float32) / 255.0\n",
    "    y = np.expand_dims(np.expand_dims(y, axis=0), axis=-1)\n",
    "    y_enhanced = model.predict(y)[0, :, :, 0]\n",
    "    y_enhanced = (y_enhanced * 255).clip(0, 255).astype(np.uint8)\n",
    "    result = cv2.merge([y_enhanced, cr, cb])\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_YCrCb2BGR)\n",
    "    return result\n",
    "\n",
    "def enhance_images(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    model = load_srcnn_model()\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is not None:\n",
    "                enhanced = enhance_image(image, model)\n",
    "                save_path = os.path.join(output_folder, f\"enhanced_{filename}\")\n",
    "                cv2.imwrite(save_path, enhanced)\n",
    "\n",
    "    print(\"모든 이미지 처리 완료!\")\n",
    "\n",
    "# 경로 지정\n",
    "input_folder = 'input_images'\n",
    "output_folder = 'output_images'\n",
    "\n",
    "enhance_images(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e17f5a-353e-420f-9784-d15b6da82e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
